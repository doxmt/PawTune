import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image

# ==============================
# âš™ï¸ ì„¤ì •
# ==============================
MODEL_PATH = "emotion_efficientnet_b0.pth"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
IMG_PATH = "test5.jpeg"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ìˆ˜ì •í•´ì„œ ì‚¬ìš©)
CLASSES = ["angry", "happy", "sad"]  # í´ë˜ìŠ¤ ì´ë¦„ (ImageFolder ìˆœì„œì™€ ê°™ì•„ì•¼ í•¨)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ==============================
# ğŸ§  ëª¨ë¸ ë¡œë“œ
# ==============================
model = models.efficientnet_b0(weights=None)
in_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(in_features, len(CLASSES))
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model = model.to(DEVICE)
model.eval()

# ==============================
# ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
# ==============================
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

img = Image.open(IMG_PATH).convert("RGB")
img_tensor = transform(img).unsqueeze(0).to(DEVICE)

# ==============================
# ğŸ” ì˜ˆì¸¡
# ==============================
with torch.no_grad():
    outputs = model(img_tensor)
    probs = torch.softmax(outputs, dim=1)[0]
    pred_idx = torch.argmax(probs).item()
    pred_label = CLASSES[pred_idx]

# ==============================
# ğŸ“Š ê²°ê³¼ ì¶œë ¥
# ==============================
print(f"ì˜ˆì¸¡ ê°ì •: {pred_label}")
print(f"í´ë˜ìŠ¤ë³„ í™•ë¥ :")
for i, cls in enumerate(CLASSES):
    print(f"  {cls:<6}: {probs[i]*100:.2f}%")
