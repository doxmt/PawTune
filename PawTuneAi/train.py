import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, models
from torch.optim import Adam
from torch.optim.lr_scheduler import StepLR

# ==============================
# âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ==============================
BATCH_SIZE = 8
EPOCHS = 20
LR = 1e-4
NUM_CLASSES = 3
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ==============================
# ğŸ“¦ ë°ì´í„°ì…‹ + ì¦ê°•
# ==============================
train_tf = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomRotation(15),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

val_tf = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

train_ds = datasets.ImageFolder("emotion_dataset/train", transform=train_tf)
val_ds = datasets.ImageFolder("emotion_dataset/val", transform=val_tf)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)

# ==============================
# ğŸ§  ëª¨ë¸ ì¤€ë¹„ (EfficientNet-B0)
# ==============================
model = models.efficientnet_b0(pretrained=True)

# Feature Extractor (ê³ ì •)
for param in model.features.parameters():
    param.requires_grad = False

# Classifier êµì²´ (3ê°œì˜ ê°ì •)
in_features = model.classifier[1].in_features
model.classifier[1] = nn.Linear(in_features, NUM_CLASSES)
model = model.to(DEVICE)

criterion = nn.CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=LR)
scheduler = StepLR(optimizer, step_size=5, gamma=0.5)

# ==============================
# ğŸƒâ€â™‚ï¸ í•™ìŠµ ë£¨í”„
# ==============================
for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    # ê²€ì¦
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)
            outputs = model(imgs)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    acc = correct / total
    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss/len(train_loader):.4f} | Val Acc: {acc*100:.2f}%")
    scheduler.step()

torch.save(model.state_dict(), "emotion_efficientnet_b0.pth")
print("âœ… í•™ìŠµ ì™„ë£Œ & ëª¨ë¸ ì €ì¥ë¨!")
